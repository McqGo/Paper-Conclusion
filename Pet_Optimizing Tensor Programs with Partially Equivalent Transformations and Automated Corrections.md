# Pet: Optimizing Tensor Programs with Partially Equivalent Transformations and Automated Corrections

# Pet: 使用部分等价变换和自动修正优化张量程序

---

## 核心思想

PET的核心思想是使用部分等价变换+完全等价变换。PET之前的编译器为了确保百分百等价，再加上验证部分等价变换的消耗很大，因此只使用了完全等价变换，但这丧失了许多优化空间，因为许多变换可以提高张量程序的运行时性能，但不会在输出张量的所有元素上保留完全等效性。而PET不仅完成完全等价变换，还实现部分等价变换。为此，它克服了一个最关键的问题——如何以尽可能少的代价验证张量程序变异后的等价性。

---

## 主要工作

本文提出第一个利用部分等价变换和自动校正来优化张量程序的 DNN 框架。PET 发现可以改进 DNN 计算的程序变换，这些变换仅具有部分功能等价性。随后，在严格的理论保证的帮助下，应用自动校正以恢复与原始程序的完全等价性。

---

## 学到的知识点

1. **部分等效变换**与完全等效变换：现有的框架只考虑完全等效的程序转换，其中新子程序在任意输入下与原始子程序在数学上等效。尽管等效程序变换在传统编译器和现代 DNN 框架中被广泛使用，但它们在性能优化方面，尤其是对于张量程序，机会有限。许多变换可以提高张量程序的运行时性能，但不会在输出张量的所有元素上保留完全等效性。我们将此类变换称为部分等效变换。性能优化部分等效变换的例子包括：（1）改变输入张量的形状或线性化顺序以提高计算效率；（2）用具有相似数学行为的更优化的运算符替换效率较低的运算符；以及（3）变换程序的图结构以实现后续的性能优化。

2. PET的三个组分：
   
   - 突变生成器：Mutation generator，为了自动发现输入子程序的部分等价变换，PET 使用突变生成器来构建潜在的程序突变体。每个突变体接受与原始子程序相同的输入张量，并生成具有相同形状的输出张量。这确保了突变体可以替换输入子程序，因此构成潜在的转换。
   
   - 突变校正器：Mutation corrector，检查输入子程序与其突变体之间的等效性，并自动生成校正内核。这些随后被应用于输出张量，以保持与输入子程序的端到端等效性。检查和纠正部分等效变换是困难的，因为程序的输出张量包含多达数百万个元素，并且每个元素都必须针对大量输入元素进行验证。PET 的一个关键贡献是一套严格的理论基础，它显著简化了这一验证过程。与检查输出张量中所有位置的程序等价性不同，PET 只需要测试几个有代表性的位置。
   
   - 程序优化器：Program optimizer，使用程序优化器来识别性能高的突变体候选者，通过有效平衡使用更好突变体的益处和额外校正核的开销。首先将任意大的输入程序在非线性算子的位置处拆分为多个小的子程序。每个子程序只包含线性算子，可以独立地进行突变。我们支持对子程序中各种算子子集进行突变，并且可以迭代地应用突变来获得更复杂的突变体。最后，我们对子程序边界进行一系列的后优化，包括冗余消除和算子融合。

3. **PET 是第一个通过利用部分等价变换并自动校正其结果来优化张量程序的框架**。PET 的输入是一个待优化的张量程序。PET 首先将输入程序拆分成更小的子程序，以减少每个子程序的探索空间，而不牺牲性能提升的机会。对于每个子程序，PET 的变异生成器通过为子程序中的 MLTP 生成可能的变异体来发现部分等效的转换。每个变异体与原始 MLTP 具有相同的输入和输出形状，因此构成部分等效的转换。为了保持对输入程序的端到端等价性，PET 的变异校正器检查变异体与其原始 MLTP 之间的等价性，并自动生成校正内核来修复变异体的输出。PET 利用严格的理论基础来简化这些具有挑战性的任务。经修正的变异体被发送到 PET 的程序优化器，该优化器将现有的完全等效变换与部分等效变换相结合，构建一个全面的程序优化搜索空间。优化器评估每个子程序的丰富变异体集合，并在其边界上应用后优化，以便在搜索空间中发现高度优化的候选者。

4. 突变生成器：该生成器以 MLTP 作为输入，并自动生成可能的突变体来替换输入 MLTP。生成算法发现一定大小范围内的有效突变体。每个生成的突变体不一定在整个输出张量上保持与输入程序的数学等价性。为了恢复功能等效性，突变校正器自动生成校正内核。

5. 突变生成算法：Mutation Generation Algorithm，我们称一个 MLTP P1 为另一个 MLTP P0 的变体，如果 P1 和 P0 具有相同数量的输入（和输出），并且每个输入（和输出）具有相同的形状。P0 和 P1 的计算不一定等效。直观地，如果 P0 是张量程序中的一个子程序，那么用 P1 替换 P0 会得到一个有效的但可能不等价的张量程序。对于给定的 MLTP P0，PET 使用给定的多线性算子集 O 作为基本构建块来生成 P0 的潜在突变体。表 1 列出了我们评估中使用的算子。该列表涵盖了各种常用的张量算子，包括计算密集型算子（卷积、矩阵乘法等）、逐元素算子（加法、乘法等）和张量操作（分割、转置等）。该集合也可以扩展到包括新的 DNN 算子。算法 1 展示了一种深度优先搜索算法，用于构建 MLTP P0 的潜在变异体。PET 从一个没有操作符且仅包含原始输入张量的空程序开始 P0。PET 通过枚举操作符类型 O 和操作符的输入张量，迭代地向当前程序添加一个新的操作符 P。输入张量可以是 P0 的初始输入张量（即算法 1 中的 I0）或先前算子的输出张量。深度优先搜索算法枚举了所有潜在的 MLTP，直到达到一定大小（称为变异深度）。对于每个突变体 P，PET 检查 P 和 P0 是否具有相同数量和形状的输入/输出。如果 P 通过此测试，则它是一个有效的突变体。

6. 三种对PET尤为重要的突变：
   
   - 重塑和转置：Reshape and transpose，张量的内存布局在优化张量程序中起着重要作用。PET 利用重塑和转置运算符来变换输入张量的形状和张量维度的线性化顺序，从而生成性能更好的变体。重塑运算符通过将单个维度分解为多个维度或将多个维度合并为一个维度来改变张量的形状。转置运算符修改张量维度的线性化顺序，例如将行优先矩阵转换为列优先矩阵。
   
   - 单操作符突变体：Single-operator mutants，用不同的、性能更高的操作符替换张量程序中效率低下的操作符。卷积和矩阵乘法等几种标准张量操作符，已经在现代硬件后端上进行了广泛的手动或自动优化。相反，它们的变体，例如带步长或膨胀的卷积，并不像标准卷积那样得到有效支持。将它们变异为具有高度优化的内核的标准对应物，可以带来性能方面的优势。然而，该变体并不完全等同于输入程序，需要在之后进行修正以恢复功能等效性。
   
   - 多操作符突变体：Multi-operator mutants，用另一个更高效的操作符集替换多个操作符的子图。这需要操作张量形状并添加适当的填充。

7. 突变校正器：Mutation Corrector，自动生成校正核。突变校正器的目标是双重的。首先，对于任何给定的 MLTP 及其变体，校正器会分析这两个程序，并识别输出张量上两个程序提供相同结果的所有区域，因此不需要任何校正。其次，对于两个输出不同的剩余区域，校正器会自动生成内核来修复变异体的输出并保持功能等效性。**PET 只需要验证少数代表性的输出位置，并使用少量随机生成的输入值。这极大地减少了验证工作量。**

8. 突变校正算法：Mutation Correction Algorithm：
   
   - 盒传播：Box propagation，首先，通过盒传播计算给定 MLTP 的框。盒传播的思想类似于深度学习中的前向和反向传播：我们根据操作符输入的框计算操作符输出张量的框，并且计算遵循程序中操作符的依赖关系进行。我们为张量的每个维度维护一组分割点，以识别其盒子的边界。对于多线性算子，我们根据其输入张量的分割点以及算子类型和超参数来推断其输出张量的分割点。
   
   - 对每个盒子对进行随机测试：Random testing for each box pair，在获得输入 MLTP P1 及其变体 P2 的所有盒子后，PET 利用相关的定理来检查来自 P1 和 P2 的每对盒子的相交区域。如果两个框没有重叠区域，则可以跳过它们。对于每个框交集，PET 检查定理 1 确定的 m + 1 个位置上两个程序的等效性，其中 m 是输出张量维度的数量。对于这 m + 1 个位置中的每一个，PET 通过分配输入张量来运行一组随机测试，这些张量的值从一个有限域 F 中均匀采样，该域包含 0 到 p − 1 之间的所有整数，其中 p = 2^31 − 1 是一个素数。为了进一步减少验证工作量，PET 包含一个缓存优化：所有框的测试共享同一组随机输入，PET 缓存并重用所有中间结果，以避免冗余计算。
   
   - 生成校正内核：Correction kernel generation，对于每个未能通过随机测试的框，PET 生成校正内核来修复其输出并恢复原始 MLTP 及其变体之间的数学等价性。因此，PET 直接利用现有的 DNN 库或内核生成技术生成校正内核。为了减少校正开销，PET 机会性地将校正内核与现有的张量运算符融合。

9. 融合校正核：Fusing Correction Kernels，校正内核可能会由于启动校正内核的成本及其有限的并行度而引入非平凡的开销。这可能会消除应用部分等效变换带来的性能提升。为了减少校正开销，PET 机会性地将校正核与其他张量运算符融合。

10. 程序优化器：Program Optimizer，程序优化器首先将输入程序拆分为多个更小的子程序，以允许高效地生成变异体。其次，为了优化每个单独的子程序，PET 通过改变要一起变异的运算符子集和变异迭代轮数来搜索丰富候选空间中的最佳变异体。最后，当将优化的子程序拼接在一起时，PET 在子程序边界上应用额外的后优化，包括冗余消除和运算符融合。
    
    - 程序拆分：Program Splitting，突变生成的复杂度随着输入程序大小的增长而迅速增加。直接对包含数百个运算符的大型张量程序进行突变几乎是不可能的。因此，PET 将输入程序拆分为多个尺寸较小的不相交子程序。但更多的分割点会导致更小的子程序，从而减少需要探索的变异候选者。在极端情况下，通过限制每个子程序仅包含少量运算符，整体复杂度将随程序大小线性增长，而不是传统的指数趋势。然而，过于激进的分裂可能会导致局部优化的变异体，这些变异体局限于子程序内部，错过了跨子程序边界的优化机会。PET在张量程序中使用非线性算子作为分割点。
    
    - 子程序优化：Subprogram Optimization，PET 通过查询变异生成器对每个子程序进行变异，并在堆结构 H 中保留估计性能最佳的前 K 个候选者，在每一步中，每个获得的突变体都会替换当前候选者中的对应子程序，以生成一个新的候选者，然后对其应用一系列的优化。
    
    - 优化后处理：Post-Optimizations，最后，需要将所有子程序的优化变体拼接在一起。除了连接它们的输入和输出张量外，我们还在子程序边界上执行了一些后优化，以进一步提高整体性能。我们观察到 PET 中的变异生成器引入了大量的 reshape 和 transpose (R/T) 运算符，尤其是在每个子程序的开头和结尾。在子程序之间融合这些 R/T 算子，以及进一步融合上述子程序优化中排除的非线性算子，都存在着机会。使用的三种后优化：
      
      - 逆运算消除：Inverses elimination，消除所有可以相互抵消的 R/T 运算符对，因此它们等效于无操作。我们将每个这样的对称为逆运算组，并在后优化阶段直接将其移除。
      
      - 算子融合：Operator fusion，PET 将剩余的连续 R/T 算子融合成单个算子（例如，R/T-DH）以降低内核启动成本。张量程序中的非线性激活也与 R/T 或其他线性算子融合。需要注意的是，运算符融合是针对非线性运算符最常用的，如果不是唯一的话，程序优化方法。PET能够恢复大部分在张量程序分割时损失的效率。
      
      - 预处理：Preprocessing，如果所有输入张量都是静态已知的，我们将预处理任何算子。

11. PET发现优化DNN计算的部分等效变换（4类优化）：
    
    - 张量级优化：Tensor-Level Optimization，通过优化张量的形状或线性化来改进 DNN 计算。作为张量级优化的一个例子，对于步长大于 1 的卷积（即输出张量是输入张量的下采样），PET 可以重新组织张量的线性化并将其步长缩减为 1，从而提高计算局部性。PET 将输入张量形状从 [1, 48, 38, 38] 变换为 [16, 48, 10, 10]，方法是将高度和宽度维度分别分成四个分区。在优化前后，IGEMM 和 FFT 分别是最有效的卷积算法。使用变换后的输入张量分别将 GPU DRAM 和 L2 访问次数减少了 100 倍和 15 倍，从而将运行时间减少了 7 倍。
    
    - 算子级优化：Operator-Level Optimization，对于在特定硬件后端实现效率较低的运算符，PET 可以利用机会用语义上类似但实现更优化的运算符替换它们。
    
    - 图级别优化：Graph-Level Optimization。
    
    - 内核融合：Kernel Fusion。
    
    ---
    
    ## 个人思考
    
    本文的核心其实只有一点——如何以尽可能少的代价验证张量程序变异后的等价性。突破点是若干相关的数学定理。PET 将原本需要检查所有输出位置相对于所有输入值组合的验证任务简化为一个更轻量级的任务，该任务只需要使用几个随机生成的输入测试几个代表性的位置即可。但同时它仍然没有保证完全正确，只是说在优化性能与正确性间做了一个取舍，但就是这个取舍，诞生了这篇论文。这启发我在今后的科研工作中，有时候可能要做个取舍，突出某个idea的某个方面，然后研究。鱼和熊掌往往不可兼得。
    
    


