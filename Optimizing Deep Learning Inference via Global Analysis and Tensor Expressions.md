# Optimizing Deep Learning Inference via Global Analysis and Tensor Expressions

# 通过全局分析和张量表达式优化深度学习推理

---

## 关键词

张量、自上而下、算子、内核

---

## 核心思想

通过对从张量表达式构建的整个张量依赖图进行数据流分析，识别 DNN 算子之间的优化机会。它将张量表达式分组为子程序，并通过语义保持转换、指令调度和张量缓冲区重用进行局部优化。

---

## 主要工作

提出了一种新的自上而下的方法，用于识别和利用跨算子边界的优化机会。有效地利用全局分析在内核级别执行局部优化，内核级别用张量表达式表示。使用低级张量表达式来执行跨越算子边界的指令优化。

---

## 学到的知识点

1. Souffle：一个开源编译器，它优化了跨运算符边界的 DNN 推理。Souffle 使用张量表达式创建全局张量依赖图，跟踪数据流和张量信息，并基于数据流分析和资源约束将计算图划分为子程序。在子程序内，Souffle 通过语义保持转换执行局部优化，找到优化的程序调度，并提高指令级并行性和数据重用。一种新颖的自上而下的方法，用于优化跨 DNN 运算符边界的推理。与自下而上的策略不同，Souffle 首先将整个计算图作为一个单一的合并内核进行处理，然后通过自顶向下的全局分析将图划分为分区，即子程序，在确定分区边界时考虑共享内存/寄存器中的数据重用和生成的指令。每个分区将被组织成一个内核。之后，在底层，Souffle 对每个子程序执行一系列语义保持转换，以简化张量表达式并消除对应内核的冗余内存访问。Souffle 引入了两种新机制：
   
   - 基于张量表达式的全局分析，用于识别关键分区点
   
   - 使用仿射变换来简化每个子程序的张量表达式的语义保持转换方法

2. **自下而上的算子/内核融合方法的局限性**：将算子融合和代码生成阶段分开。这会导致算子被错误地放置到不同的内核中，从而导致额外的内存访问开销，并阻止其他可能的优化。

3. 与现有的自下而上融合方法相比，Souffle自上而下方法的优势在于它通过考虑内核生成的代码来全局确定内核边界。

4. Souffle的工作流程：
   
   - 基于张量表达式的全局分析：Tensor-expression-based global analysis，Souffle 对从整个 DNN 模型生成的张量依赖图进行全局依赖分析。它利用张量表达式 (TE) 来编码算子和张量的数据流信息。通过将更高层的算子映射到更简单的 TE，Souffle 在这些 TE 周围执行数据流分析和代码优化，简化了分析和优化的复杂性，并产生了更好的代码。TEs 提供简洁的语义，使我们能够将分析和优化复杂算子的任务转化为更易于管理的分析和优化更简单数学表达式的任务。由于 Souffle 的分析是在 TEs 上进行的，并且没有对底层库调用进行任何假设，因此它可以跨复杂算子进行优化，即使算子具有复杂的数据依赖关系，例如多对多，而其他方法无法做到这一点。
   
   - 语义保持转换：Semantic-preserving transformation，计算图被划分为多个子程序，每个子程序被映射到一个内核。但是，每个子程序包含大量TE，这会导致这些TE之间出现大量冗余内存访问。因此，Souffle 应用仿射变换将多个 TE 合并成一个 TE，从而消除冗余的内存访问。此过程在子程序中执行，并依赖于基于 TE 的全局分析。由于张量表达式以简单形式精确地描述了运算符的数学计算，因此变换是完全自动化的且灵活的。
   
   - 将所有内容整合起来：Putting it all together，Souffle 首先使用 TEs 对整个 DNN 模型的张量依赖图进行数据流分析。这种分析捕获了诸如张量形状和跨运算符边界的生存范围等基本信息，从而允许进行精确的逐元素分析以推断数据依赖关系。Souffle 然后使用编译器启发式方法将 TEs 分割成子程序，并使用语义保持的数学变换对每个子程序进行局部优化，以减少内存访问。通过考虑子程序 TEs 的计算特性，可以找到优化的子程序调度。凭借 TE 级别精确的依赖信息，Souffle 可以通过重用张量缓冲区来优化内存访问延迟，并通过重叠内存加载和算术指令来提高指令级并行性。由于 Souffle 的代码优化基于融合算子的子程序而不是单个算子，因此消除了算子的优化边界。

5. Souffle 在 TE 子程序中支持两种类型的优化:
   
   - 指令级优化：Instruction-level optimization，旨在将异步 GPU 内存加载与算术指令重叠。需要注意的是，这种流水线执行是在多个 TE 之间进行的，如果没有全局数据依赖性分析，则无法进行优化。Souffle 将指令分组到一个融合的子程序中，该子程序包含多个原始运算符，以并行执行内存和算术指令。这是通过跨运算符边界调度负载/存储和计算指令以进行流水线执行来实现的。
   
   - 张量重用优化：Tensor reuse optimization，ouffle 在底层调度器（本工作中为 Ansor）生成子程序内的 TE 调度后执行子程序级优化。Souffle 使用一个简单的软件管理缓存，通过最近最少使用 (LRU) 策略在运行时从共享内存中替换张量缓冲区（例如，矩阵和向量），最大限度地提高了跨 TEs 的张量缓冲区重用。它线性扫描指令，直到共享内存耗尽，将共享内存溢出到全局内存，并在共享内存耗尽时添加内存屏障。

6. 循环融合：Loop fusion，循环融合通常用于提高 CPU 程序的性能。最近的研究也利用内核融合来优化 GPU 程序，方法是减少进出片外内存的数据流量。

7. DNN 编译器中的算子融合：Operator fusion in DNN compilers，算子融合可以通过提高数据重用和减少片上数据流量来提高性能。为了寻找融合机会，DNNFusion 对算子进行分类，并根据其分类定义规则进行融合。

8. 全局分析和融合优化：Global analysis and fusion optimization，将高级运算符降低到低级张量表达式 (TE)，TE 具有简洁的语义。在 TE 上进行操作，而不是假设高级运算符，使 Souffle 能够灵活地跨运算符边界进行优化。

---

## 个人思考

Souffle作为一种新型DNN推理优化工具，其自上而下的方法突破了传统自下而上的算子融合策略，通过全局张量依赖图的构建和数据流分析，有效地识别并利用跨算子边界的优化机会。Souffle不仅将计算图划分为子程序，还通过语义保持的转换消除了冗余内存访问，从而提高了指令级并行性和数据重用。这种方法特别适用于处理复杂的数据依赖关系，因为它使用了简化的低级张量表达式（TE），使得优化过程更加灵活和可管理。

此外，Souffle的设计考虑了多个优化层面，包括指令级优化和张量重用优化，确保了在不同硬件上都能有效执行。这种优化不仅提升了性能，还有效减少了内存带宽的压力，使其在现代深度学习应用中显得尤为重要。通过将算子和内核融合过程整合在一起，Souffle为DNN编译器的发展提供了一条新路径，展现了在多层次抽象中实现高效优化的潜力。
