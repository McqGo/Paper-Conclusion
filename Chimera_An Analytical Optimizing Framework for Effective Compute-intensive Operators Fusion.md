# Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion

# Chimera：一种用于有效融合计算密集型算子的分析优化框架

---

## 核心思想



---

## 主要工作

提出了一种分析模型来评估内存绑定计算密集型算子链的数据移动量，融合内存绑定计算密集型算子，优化块间数据移动和块内计算，生成高效的融合内核以提高局部性。使用可替换的微内核来支持不同的加速器，并采用分析方法来优化微内核。

---

## 学到的知识点

1. 机器学习中存在两种类型的运算符：
   
   - 计算密集型运算符：compute-intensive operators，例如，GEMM 和卷积
   
   - 内存密集型运算符：memory-intensive operators，例如，ReLU 和 softmax
   
   在新兴的机器学习模型中，计算密集型运算符通常以链式结构组织。随着硬件的不断专业化，计算性能和内存带宽之间的差距越来越大。因此，许多计算密集型算子链的实现受到内存带宽的限制，生成融合内核以提高这些计算密集型算子的局部性变得必要。然而，现有的机器学习编译器缺乏对不同加速器上计算密集型算子链的精确分析和高效优化。因此，它们通常会为这些算子链生成次优性能。（**Chimera的诞生原因**）

2. Chimera：有效地提高不同硬件加速器上计算密集型算子链的局部性。在 Chimera 中，每个计算密集型算子由一系列计算块组成。为了生成算子链的有效融合内核，需要对块间和块内进行优化。
   
   - 块间优化：Chimera 使用分析模型来最小化块之间的数据移动量，从而决定优化的块执行顺序。具体来说，Chimera 枚举不同的块执行顺序，并分析估计块之间输入/输出数据移动量。之后，Chimera 选择数据移动量最小的执行顺序，从而实现最佳数据局部性。
   
   - 块内优化：Chimera 使用统一的可替换微内核，为不同的加速器应用硬件特定的优化。Chimera 应用了硬件特定的优化。为了处理硬件的多样性，Chimera 使用一个统一的可替换微内核作为高级抽象，并在代码生成期间为不同的硬件架构生成低级微内核实现。
   
   最后，来自不同计算密集型算子的计算块根据块执行顺序交织在一起，Chimera 为计算密集型算子链生成融合内核，并使用特定于硬件的微内核生成低级设备代码。

3. 需要对内存绑定计算密集型算子进行优化：随着硬件专业化的不断发展，专用计算核心与芯片外部内存之间的速度差距越来越明显。因此，许多计算密集型运算受到内存带宽的限制。此外，计算性能和内存带宽之间的差距预计将继续扩大。许多计算密集型运算符（例如，Transformer 中的批量 GEMM）的内存绑定实现正成为性能瓶颈。因此，需要对这些内存绑定计算密集型算子进行优化，以提高局部性并减少对内存带宽的压力。**而内核融合是有效方法**。

4. **Chimera 的整体工作流程**：Chimera 由四个部分组成：块分解、块间重排序、块内调度和代码生成。Chimera 的输入是机器学习中的计算 DAG（由领域特定语言描述）。每个DAG中的操作首先被分解为一系列计算块。然后，通过使用分析模型选择优化的块执行顺序。该分析模型仅依赖于对稠密张量的循环嵌套的分析。因此，对于不同的模型拓扑结构（例如，不同的张量或算子数量）来说，这是通用的。块之间的原始依赖关系都保留下来，以便 Chimera 选择的所有块排序都是有效的。之后，通过使用可替换的微内核来应用块内优化。Chimera支持不同的硬件。

5. 块间优化：INTER-BLOCK OPTIMIZATION，2种：
   
   - 块分解：Block Decomposition，机器学习模型中每个计算密集型算子可以分解为一系列计算块。分解是通过循环平铺和重排序实现的。计算块包含一个小的循环嵌套，它访问输入数据的块以生成输出数据的块。通常，一个计算块可以放置在一个处理核心上，并且一个块的所有访问数据都可以由片上本地内存容纳。每个计算块的大小由分解参数控制。在块分解中，我们的目标是选择最佳的块分解参数，以最大程度地提高整体性能。先前的工作提出独立计算这些参数，以平衡不同块的计算开销。但分解参数不能独立选择，因为它们会与块执行顺序一起影响整体数据重用。
   
   - 块重排序：Block Reordering，通过块重排序最小化数据移动量我们在块间优化中的目标是找到最优的块执行顺序和分解参数，以最小化总数据移动量。最小化数据移动量等同于最大化数据局部性（或重用）。来自不同算子的计算块可以重新排序以获得更好的数据重用，对于更多计算密集型算子，分析方法保持类似。需要注意的是，对内存密集型算子没有约束。对于内存密集型操作符，我们使用先前工作中的标准融合优化。

6. **寻找优化块执行顺序（即循环置换选择）的主要思想**：针对每个置换选择，用解析的方式表示数据移动量与分解参数之间的关系。通过这样做，我们可以通过找到合适的分解参数来最小化数据移动量，并获得在所有候选方案中数据移动量最小的优化置换选择。

7. 多级存储层次优化：Optimization for Multi-level Memory Hierarchy，前面只考虑了一级内存。对于多级片上内存，我们的计算块可以递归地进一步分解成子块。这些子块的重新排序将影响更高级别片上内存中的数据移动量。我们还根据硬件配置对跨不同内存层的数据移动成本进行建模。

8. 块内优化：INTRA-BLOCK OPTIMIZATION，Chimera 中针对特定硬件的优化。不同的硬件加速器需要不同的优化才能实现高性能。Chimera 利用可替换的微内核来处理硬件的多样性。
   
   - 可替换微内核：Replaceable Micro Kernels，不同加速器的编程模型和优化方法各不相同。例如，为了实现一个高性能的矩阵乘法微内核：
     
     - 在 CPU 上，我们需要使用汇编语言编程来利用 SIMD 单元
     
     - 在 GPU 上，我们需要使用 Tensor Core 内在函数将计算映射到 Tensor Core 单元
     
     - 在 NPU 上，我们需要在循环中添加编译指示，以指示底层编译器生成加速器指令
     
     为了通过统一的方式处理硬件多样性，Chimera 使用可替换的微内核，这些微内核可扩展且灵活，适用于不同的硬件后端。
   
   - 微内核代码生成：Micro Kernel Code Generation，微内核的代码生成与算子紧密耦合。这里，我们关注矩阵乘法微内核。内核，可被各种计算密集型算子重用，包括 GEMM、批量 GEMM 和卷积。

---


