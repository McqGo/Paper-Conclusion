# TVM: An Automated End-to-End Optimizing Compiler for Deep Learning

# TVM：针对深度学习的端到端自动优化编译器

---

## 核心思想

TVM在计算图和算子上做优化，分别是图级优化与算子级优化，同时继承Halide的“将算法的描述和调度分离“这一思想用以在每个硬件后端生成许多有效的实现并选择一个优化的实现，为每个算子生成高效的代码。TVM采用基于学习的成本建模方法寻找最佳调度方案，并使用调度来表示从张量表达式到低级代码的特定映射。

---

## 主要工作

该论文是对TVM（Tensor Virtual Machine，它是一个深度学习编译框架，用于优化和部署深度学习模型。TVM旨在通过自动化的方式提高模型在不同硬件上的运行效率。）的总体介绍，并通过一系列实验验证它相对于现有的深度学习框架（依赖于高度优化的库）优越性。主要介绍了**TVM的产生背景**（DL应用到不同硬件设备的需求日益增长，如何高效地将DL框架部署到数量日益增长的硬件设备？如何尽可能地优化生成的代码？）、**TVM解决的DL特有的优化问题**（高级算子融合、内存延迟隐藏、硬件原语的映射、并行性、张量表达式、自动调优）与**TVM采用基于学习的成本建模方法来快速探索代码优化，从而自动优化低级程序以适应硬件特性**（目标是找到最佳调度方案）。

---

## 学到的知识点

1. accelerator一般都倾向于设计成精简的控制，我认为是在硬件电路层面设计越简单越好，那么复杂性就留给了编译器，比如将调度问题给编译器解决，以生成能够显式控制流水线依赖关系的代码，从而隐藏内存访问延迟。

2. **Halide的设计思想是“将算法的描述和调度分离”，TVM继承了这一思想。**

3. DL框架-->计算图-高级图重写->优化的计算图-算子级优化->优化后的低级循环程序。![](C:\Users\MCQSW\AppData\Roaming\marktext\images\2024-10-11-15-09-47-image.png)

4. TVM编译后的运行时模块包含三个组件：最终优化后的计算图（graph）、生成的算子(lib)与模型参数(params)。

5. DL框架表示程序的常用方法是计算图（Computational Graph），与LLVM IR的主要区别在于其中间数据项是大型的多维张量，但相似点是计算图可以转化成功能等效的图。

6. TVM在计算图上做高级优化，计算图的节点表示对张量或程序输入的操作，边表示操作间的数据依赖关系。图级优化包括：算子融合（operator fusion）、常量折叠（constant-folding）、静态内存规划（static memory planning pass）、数据布局转换（data layout transformations）。

7. TVM引入张量表达式（Tensor Expression）语言来支持代码自动生成。张量表达式语言与高级计算图不同，高级计算图中张量操作的实现是不透明的。张量表达式语言支持常见的算术数学运算，涵盖常见的DL算子模式，但没有指定循环结构和许多其他执行细节，这为各种后端添加机器有关优化提供了灵活性。

8. TVM使用调度来表示从张量表达式到低级代码的特定映射，而调度通过逐步应用基本变换（调度原语）构建，这些变换保留程序的逻辑等价性。

9. 在进行调度变换时，TVM会使用数据结构跟踪循环结构和其他信息，这些信息帮助生成给定最终时间表的低级代码。

10. TVM的张量表达式借鉴了Halide、Darkroom和TACO。

11. 并行性是提高DL中计算密集型效率的关键，现代GPU提供了大规模并行性，调度变换中需要加入并行模式。目前，大多数解决方案采用**嵌套并行**（nested parallelism）的模型，一种fork-join的形式，它是一种无共享嵌套并行（sharednothing nested parallelism），因为在一个并行计算阶段内，一个工作线程无法查看其兄弟线程的数据。该模型需要一个并行调度原语来并行化数据并行任务；每个任务可以进一步递归地细分为子任务，以利用目标架构的多级线程层次结构（例如，GPU 中的线程组）。

12. 无共享的另一种选择是协作获取数据。具体来说，线程组可以协作获取它们所需的所有数据并将其放置到共享内存空间中。此优化可以利用 GPU 内存层次结构，并通过共享内存区域实现线程间的数据重用。TVM 使用调度原语支持这种众所周知的 GPU 优化，以实现最佳性能。

13. **张量化**（Tensorization）将调度与特定硬件原语解耦，使 TVM 易于扩展以支持新的硬件架构。张量化调度生成的代码与高性能计算中的实践相一致：将复杂操作分解为一系列微内核调用。

14. **延迟隐藏**（Latency hiding）是指将内存操作与计算重叠以最大化内存和计算资源利用率的过程。它需要根据目标硬件后端采用不同的策略。在 CPU 上，延迟隐藏是通过多线程  或硬件预取隐式实现的。GPU 依赖于对许多线程束的快速上下文切换。相比之下，像 TPU这样的专用深度学习加速器通常更倾向于使用更精简的控制，采用解耦访问执行 (DAE) 架构，并将细粒度同步问题卸载到软件中。

15. TVM 为与每一层相关的特定输入形状和布局创建了一个专门的算子。TVM拥有一个自动调度优化器，它包含两个主要组件：一个调度探索器，用于提出有希望的新配置；以及一个机器学习成本模型，用于预测给定配置的性能。

16. **从一个庞大的配置空间中找到最佳调度方案的一种方法是通过黑盒优化，即自动调优。另一种方法是构建一个预定义的成本模型来指导特定硬件后端的搜索，而不是运行所有可能性并测量它们的性能**。由于现代硬件的复杂性不断增加，这种方法很繁琐，因为一个完美的成本模型会考虑所有影响性能的因素：内存访问模式、数据重用、流水线依赖关系和线程模式等。此外，每个新的硬件目标都需要一个新的（预定义）成本模型。![](C:\Users\MCQSW\AppData\Roaming\marktext\images\2024-10-11-15-53-28-image.png)
    
    一个调度探索器使用基于机器学习的成本模型来检查调度空间，并通过 RPC 选择在分布式设备集群上运行的实验。为了提高其预测能力，机器学习模型会定期使用存储在数据库中的收集数据进行更新。

---

## 个人思考

这是我阅读的第一篇AI编译器的论文，所以在阅读过程中，我经常把TVM与传统编译框架之一的LLVM做比较，并通过不同点与相似点去思考TVM。我认为二者的核心不同点是TVM的优化对象与优化方法。TVM的输入是DL框架，因此其优化方法与DL紧密相关，同时TVM采取了基于学习的成本建模方法来快速探索代码优化。二者的相似点之一就是它们都需要进行机器有关优化，要充分考虑硬件设备的架构，再就是二者的部分优化方法相似，毕竟归根结底，TVM还是一个编译器。
