# Unity: Accelerating DNN Training Through Joint Optimization of Algebraic Transformations and Parallelization

# Unity: 通过代数变换和并行化的联合优化加速 DNN 训练

---

## 核心思想

将代数变换和并行化都表示为统一的并行计算图上的图替换，然后使用分层搜索算法来有效地识别哪种替换组合能获得最佳性能。

---

## 主要工作

Unity，一个在分布式 DNN 训练中联合优化代数变换和并行化的系统。Unity 将并行化和代数变换都表示为统一图表示上的替换，使用一种新颖的分层搜索算法来识别优化的替换序列，并扩展到大量 GPU 和复杂的 DNN。

---

## 学到的知识点

1. 减少DNN训练时间的两种关键优化：
   
   - 代数变换：Algebraic transformations，利用算子恒等式以更有效的方式执行底层计算，但忽略了训练的并行化和分布。代数变换的常见例子包括算子融合，它将两个算子合并成一个语义等效的算子，其计算效率更高；以及算子重排序，其中算子集合的结合律或交换律允许它们被重新排序成更有效的配置或暴露进一步的优化机会。
   
   - 并行化：Parallelization，将操作符分布在多个设备上，但不会改变底层计算的执行方式。DNN 训练利用了一种名为“分治”的并行化类别，其中操作符的每个分布式子计算必须执行相同的计算，并且可能仅在它所消耗的输入数据方面有所不同。DNN 训练中的张量计算特别适合这种形式的并行化。

2. 并行化：Parallelization，张量代数的高度并行性为并行化 DNN 训练提供了许多机会。DNN 系统中利用的六种主要并行形式：
   
   - 数据并行：Data parallelism，在每个设备上保留整个 DNN 模型的副本，并为每个设备分配训练数据的子集。
   
   - 模型并行：Model parallelism，将 DNN 模型划分为不相交的子模型，并在专用设备上训练每个子模型。
   
   - 空间并行：Spatial parallelism，将张量的空间维度（例如，图像的高度和宽度）划分为多个分区，每个分区分配给一个特定的设备。空间并行通常需要同步设备之间共享的元素（例如，不同子图像边界处的共享像素）。
   
   - 约简并行：Reduction parallelism，利用了张量代数运算符的线性性。对于矩阵乘法 C = A × B，约简并行将 A 沿其列拆分，将 B 沿其行拆分，如下所示：A = [A1, . . . , An]，B = [BT 1 , . . . , BT n ]T 矩阵乘法分布在 n 个设备上，第 i 个设备计算 Ci = Ai × Bi。之后额外的约简恢复原始结果：C = ∑i Ci。
   
   - 管道并行：Pipeline parallelism，利用了跨不同训练迭代并行化的机会。
   
   - 算子特定并行化：引入新的 DNN 算子提供了算子特定并行化的机会。
   
   **大多数并行化并非纯粹的性能优化，而是不同成本指标之间的权衡**。例如，应用数据并行性会减少每个设备的计算时间，但会增加存储和同步模型参数的内存使用量和数据移动量。因此，DNN 运算符通常需要结合这些并行形式才能实现最佳性能。

3. 代数变换：Algebraic Transformations，比如算子融合。小的代数变换可以组合起来产生巨大的变化。PCG 允许 Unity 将代数变换和并行化都视为对公共图的图替换。尽管 PCG 不是第一个将计算和并行化合并到单个图中的方法，但 PCG 专为优化而设计，因此在关键方面与之前的统一图表示方法有所不同。

4. 并行计算图 (PCG)：分布式 DNN 训练的统一表示，它能够同时表达计算、并行性和通信。PCG通过允许节点表示并行化变化（除了数学张量运算）以及边表示张量数据的分布式移动（除了数据依赖性）来扩展现有的计算图表示。 添加了一组并行化运算符，允许 PCG表达所有现有的并行化策略，并提供对数据移动及其在训练期间相关成本的显式表示。此外，PCG 中的每个算子都与一个机器映射相关联，表示算子的执行如何映射到并行机器中的各个处理器。

5. 早期的工作依赖于程序员手动确定要应用的正确优化。虽然手动优化允许对模型的性能进行细粒度控制，但它需要专家花费大量时间进行调优才能获得良好的性能。随着模型设计新发展的步伐加快，手动优化难以扩展到最常用的模型之外。**最近的研究集中在优化自动化方面**。

6. **代数变换与并行化的执行顺序问题**：**由于代数变换可以引入新的操作或替换现有操作，在分配并行化后运行代数优化会导致最终解决方案中出现没有分配并行化的操作（如果操作被创建）或无效的并行化（如果操作被替换）**。可以使用变通方法通过使用默认并行化策略或复制附近操作符的策略来修复无效的解决方案，但很容易找到这些变通方法导致次优解决方案的情况。**因此，在并行化之前应用代数优化是唯一的选择，但它可能会错过重要的优化机会。**

7. 联合优化：joint optimization，联合优化对于最大化性能是必要的。现有框架对模型的计算图进行优化。如上所述，代数变换可能会导致计算图中的运算符具有未分配或无效的并行化。为了防止搜索过程中出现此类无效解，我们需要一种表示方法，该方法允许代数变换在应用之前考虑当前的并行化。现有的基于搜索的方法已经难以扩展到大型模型和 GPU 数量。仅针对代数变换的改进已经取得了一些进展 [62]，但这些解决方案的复杂性使得添加并行化成为一项艰巨的任务。同时考虑两种优化类别只会通过呈指数级增加搜索空间大小来加剧这个问题。为了使联合优化变得实用，搜索算法必须在过去技术的可扩展性方面有所改进。**为此，Unity将代数变换和并行化都表示为统一的并行计算图上的图替换，然后使用分层搜索算法来有效地识别哪种替换组合能获得最佳性能**。

8. 统一图表示：Uniﬁed graph representation，选择使用 PCG 而不是带注释的计算图，是因为 PCG 的表示形式更容易用于联合搜索，而不是因为带注释的计算图存在根本性局限。理论上，存在与 PCG 同构的注释语言，但设计这种语言的尝试很快就会遇到许多困难。通过一组小的并行化操作符来表示这些模式，也使 Unity 能够轻松地识别和优化常见的通信模式。

9. 图替换：Graph Substitutions。由于 Unity 将代数变换和并行化都表示为图替换，因此联合优化的有效性依赖于拥有适当的图替换集。潜在替换的数量随着规模呈指数增长，因此 Unity 将大型和复杂的代数变换以及并行化策略表示为小型 PCG 替换的组合。替换生成。为了减少支持新并行化策略的工程量，Unity 自动生成并正式验证所有大小固定的有效 PCG 替换，作为“基集”，搜索算法可以从中构建复杂的优化。这使得 Unity 不仅能够自动发现代数变换和并行化策略，还能找到先前方法遗漏的两种方法的全新混合。为此，Unity 采用了 TASO 的超级优化方法。发现替换：
   
   - 首先使用快速启发式算法识别候选替换，然后使用更昂贵的形式化验证来确保正确性。为了找到候选替换，Unity 枚举了所有可能的 PCG，直到达到固定大小。需要注意的是，此固定大小不会限制 Unity 可以应用的变换的大小，因为许多较大的替换是由较小的替换组成的。
   
   - 对于每个生成的 PCG，Unity 会计算一个指纹：一个对 PCG 在一些固定输入张量上评估后生成的输出张量进行哈希运算的结果。为了让 Unity 能够考虑并行化，我们在 TASO中扩展了指纹函数，将每个张量维度的并行化程度也纳入其中。如果两个 PCG 具有相同的指纹，则它们被视为候选替换。

10. 替换验证：Substitution veriﬁcation，与 TASO 类似，Unity 使用自动定理证明器正式验证新的替换。

11. **遵循 TASO 的方法来开发算子的并行化属性：作者尝试使用 Z3 正式验证所有候选替换，当替换无法验证但正确时，作者添加缺少的算子属性。**

12. Unity 的搜索算法：
    
    - 中间层（替换选择）：Unity 使用 TASO中的基于成本的回溯搜索算法来识别一个替换序列，该序列可以最小化输入 PCG 的执行时间。Unity 维持一个候选 PCG 的队列，该队列按其执行时间排序，并且直到队列为空或固定预算超过为止，Unity 迭代地从队列中移除最佳候选，并使用它通过在 PCG 中的每个位置应用所有可用的替换（在适用时）来生成新的候选。具有执行时间比目前为止看到的最佳候选 PCG 差阈值因子倍的候选 PCG 将被剪枝，而其余的将被插入队列中。阈值因子允许用户平衡搜索时间和探索量。该算法允许 Unity 探索任意替换序列，但需要一个精确的成本估算器来评估每个候选 PCG 的执行时间。由于 PCG 仅包含每个运算符的并行化，而不包含分配给它的设备（即机器映射），因此该成本估算器必须首先确定一个优化的机器映射。为了识别这种映射，必须使用一种高效的算法，因为成本估算器会为每个候选 PCG 调用。而该优化机器映射由算法进行查找。
    
    - 最低层（ 寻找最优机器映射）：Unity 搜索算法的最低级别识别出候选 PCG 的优化机器映射。该级别背后的关键观察是，大多数现代 DNN 架构由独立的并行计算链组成。Unity 利用这种结构，通过序列和并行图分割，分别递归地将这些线性链和并行链分解成独立的子图。
    
    - 最高层（图分割）：
      
      - 序列图分割：sequence graph split
      
      - 并行图分割：parallel graph split
      
      作为一项额外的优化，Unity 为所有子图维护了一个选定机器映射的缓存。由于替换选择为每个替换生成一个新的候选，并且每个替换只修改 PCG 的一小部分，因此许多候选 PCG 的大部分子图与其他候选共享。这使得 Unity 可以跳过计算除正在考虑的替换所修改的 PCG 部分之外的所有部分的成本和机器映射。

13. 图扩展：Scaling to Large Graphs，即使使用动态规划算法和跨调用缓存，到目前为止描述的搜索算法仍然无法扩展到大型模型。简单的图分割会将所有拆分的并行度降低到 1，从而消除许多常见且重要的并行化策略，例如在整个模型中使用数据并行化。Unity 通过显式地搜索每个分割位置的最佳并行化来解决这个问题。更具体地说，对于跨分割通信的张量的每个可能的划分，Unity 在第一个子图的输出和第二个子图的输入都必须与正在考虑的划分匹配的条件下，优化由此产生的两个子图。当任一子图不满足此条件时，将插入并行化运算符以确保将由分区更改引起的任何通信成本考虑在内。该方法适用于分割和合并，但在复制和归约方面遇到了问题。例如，考虑张量跨越分割位置的情况，其副本度由搜索算法固定为 2。为了强制第一个子图输出这种格式的张量，搜索算法可以在其最终操作中插入一个复制操作，类似地，该算法可以在第二个子图的第一个操作中插入一个归约操作。然而，这将导致张量被错误地缩放 2 倍！核心问题在于，与 Partition 和 Combine 不同，Replicate 和 Reduce 并非彼此的逆运算。幸运的是，由于跨计算图多个节点的约简并行在实践中很少有用，因此我们将跨拆分的划分限制为仅那些副本度为 1 的划分为了减少这些拆分所阻止的代数变换次数，Unity 遵循 MetaFlow，并选择拆分位置，这些位置在保持最小子图大小为 k 的情况下，会破坏最少的替换。5 因此，图拆分将候选 PCG 的最坏情况数量从 g 中的指数级减少到 g 中的线性级，具体来说，从 O (2gs) 减少到 O  gkp × 2ks，其中 p 是有效张量划分数量。

14. 流水线并行：Pipeline parallelism。在考虑流水线并行时，Unity 采用 1F1B 调度（即在每个设备上交错前向和后向微批次）以及来自 PipeDream-2BW的权重更新语义，这既能实现高训练吞吐量，又能实现低内存占用。为了减少搜索空间，Unity 只考虑将流水线并行应用于 PCG 中所有算子的策略，因为 PCG 中的非流水线并行算子会禁用流水线并行的优势。Unity 仅考虑顺序流水线并行，其中每个阶段仅与流水线中的单个下一阶段通信（最后一个阶段除外，它在正向处理后直接执行反向传播）。假设一个 mini-batch 中的微批次数量远大于流水线阶段的数量，因此可以忽略流水线初始化带来的额外延迟。这些约束允许 Unity 探索一个包含现有流水线并行策略的全面搜索空间，同时保持合理的搜索时间。搜索算法也略有修改：不再使用每次迭代的运行时间作为吞吐量的代理，而是直接最大化吞吐量。
    
    ---
    
    ## 个人思考
    
    编译器的优化基于IR，所以在往后的研究中，如果发现优化遇见了瓶颈，比如本文的并行化与代数变换不能进行很好的联合优化的话，那么要考虑是否换种合适的IR。同时，许多idea可能才会形成一篇论文，而这些idea可能不是由自己一个人全部发现的，时刻追踪领域前沿是个必要的选择。**自动化替代手动是编译器发展的趋势**。因此，AI搜索算法是非常有必要深入学习的。
    
    
    
    
