# Roller: Fast and Efficient Tensor Compilation for Deep Learning

# Roller: 深度学习中快速高效的张量编译

---

## 关键词

张量、IR、算子、流水线、性能评估

---

## 核心思想

ROLLER 采用递归的 rTile 基于构建算法生成基于 rTile 的程序 (rProgram)，其性能可以通过微性能模型进行高效评估，而无需在真实设备上进行评估。因此，ROLLER 可以在几秒钟内生成高效的内核。ROLLER不像多层嵌套循环那样处理DNN算子的计算，而是将其视为数据处理管道，其中数据块（张量的部分）在具有并行执行单元和多层内存层次结构的抽象硬件中移动和处理。生成高效内核程序的目标就变成了提高流水线的吞吐量。

---

## 主要工作

ROLLER 通过递归的 rTile 构建算法生成高效的张量程序（rProgram），并使用微性能模型进行快速性能评估，而无需在实际设备上测试。这种方法将深度神经网络算子视为数据处理管道，优化了数据块在抽象硬件中的移动与处理，显著提升了流水线的吞吐量。rTile 抽象与硬件特性对齐，确保了高效的内存访问与计算性能。ROLLER 的设计强调了对齐的重要性，并通过微性能模型简化了性能评估过程，为加速器编程提供了一种高效的解决方案。

---

## 学到的知识点

1. **DNN 编译器将 DNN 算子视为张量计算，然后将其转换为嵌套的多级循环，这些循环迭代不同轴（维度）上每个张量元素的计算。**

2. **Roller与硬件的适配**：为了使加速器高效执行，数据块的形状应与硬件特性相一致，包括内存库、内存事务长度和最小可调度单元（例如，GPU 中的warp大小）。为了实现跨多个硬件特性的完全对齐，可用的块形状是有限的。更重要的是，以对齐作为约束，为了最大化流水线的吞吐量，只需要构建一个能够饱和加速器执行单元的对齐的瓦片形状。这个构建过程比解决原始的无约束组合优化问题要有效得多。

3. **对齐流水线的性能高度可预测**：对齐流水线下的关键性能指标（例如，内存吞吐量）可以从硬件规格（或通过微基准测试）推导出来。这极大地简化了各种对齐配置下的性能评估，消除了对复杂成本模型和/或在每个对齐配置上进行昂贵的基于硬件的评估的需求。

4.  **rTile**：一种新的抽象，它封装了与硬件加速器关键特性和输入张量形状一致的数据块形状，张量计算的基本计算单元。然后，数据处理管道可以描述为一个基于 rTile 的程序（也称为 rProgram），该程序由三个接口组成：Load、Store 和 Compute，它们针对 rTile 运行。为了构建一个高效的 r程序，ROLLER 采用了一种先扩展后分片的策略。它首先执行扩展过程，该过程采用递归的基于 rTile 的构建算法来逐步增加 rTile 形状的大小，从而构建一个能够饱和加速器单个执行单元（例如，NVIDIA GPU 中的 SM，流式多处理器）的 rProgram。然后，它执行扩展过程，该过程简单地将生成的 rProgram 复制到其他并行执行单元，**这得益于深度学习计算模式和加速器中并行执行单元的同质性**。**rTile 的一个独特属性是它必须与给定张量表达式中的底层硬件特性和张量形状对齐**。

5. **影响流水线中所有步骤性能的关键因素是瓦片形状以及其在单维内存空间中的对应布局。**

6. Roller工作流程：
   
   - 接收一个描述为张量表达式的算子
   
   - 从张量表达式中提取张量形状，并利用硬件规格构建 rTiles，即硬件对齐的构建块
   
   - 基于 rTiles，ROLLER 提出了一种“先扩展后扩展”的递归构建算法，以生成描述数据处理管道的有效张量程序（称为 rProgram），在生成 rProgram 时，构建算法通过微性能模型评估构建的 rProgram 的性能来识别良好的 rTile 配置。该模型建立在通过硬件抽象层描述的设备之上，该层仅公开与 rTile 相关的接口：加载、计算和存储
   
   - 构建的 rProgram 通过代码生成器实现，以生成对应于特定设备的最终内核代码

7. **rTile与硬件的适配**：
   
   - 与硬件执行单元对齐：Alignment with the hardware execution unit，rTile 的形状必须与它运行的执行单元的并行性对齐。在流式多处理器 (SM) 上执行的 rTile 应将其大小与 SM 上的执行单元数量对齐。数据块的形状应与内存事务的长度对齐，以实现最佳的内存访问。我们应该保证其首要维度（例如，在行优先张量中，最内层的维度）是内存事务长度的倍数。在 ROLLER 中，张量以缓存对齐的方式分配。因此，rTile 可以避免任何浪费的交易读取，因为它的形状与内存交易对齐。
   
   - 与内存库对齐：Alignment with memory bank，数据块的内存布局应该使其步长与内存库对齐，以避免读取冲突。
   
   - 与张量形状对齐：Alignment with tensor shape，rTile 的形状应该与输入张量表达式的张量形状对齐。否则，计算无法被 rTile 均匀划分，从而浪费计算资源或导致繁重的边界检查开销。

8. 张量程序构建：Tensor Program Construction，r瓦片程序。鉴于 rTile 和现代加速器的分层内存结构，张量计算可以自然地视为一个流式数据处理管道。该计算从最低内存层通过内存层次结构加载数据瓦片（在 rTile 中指定）到最高层，在加速器的执行单元上执行 rTile 计算，并将结果数据瓦片存储回最低内存层。对于每个内存层，定义了一个特定的 rTile 以与该内存层的特性相一致。因此，ROLLER 将张量计算描述为具有分层 rTile 配置的数据处理管道，称为 rTile 程序（即 r程序）。

9.  **r程序的有效评估**：Efﬁcient Evaluation of an rProgram，ROLLER 基于硬件抽象层 (HAL) 中描述的设备构建了一个微性能模型。HAL 将加速器建模为多个并行执行单元，并具有分层内存层。HAL 公开了三个基于 rTile 的接口：加载、计算和存储。执行单元被抽象为一个 rTile 执行单元 (TEU)，它通过计算接口计算数据块。多个 TEU 可以组织成一个组，它们协作加载和存储数据块。HAL 将不同的内存层，例如寄存器、共享内存、DRAM，视为统一类型，并公开影响数据块移动性能的硬件规格。规范包括内存容量、事务长度、缓存行大小和内存组数量。

10. **微性能模型**：Micro performance model，借助硬件抽象层，ROLLER 可以轻松推导出 rTile（以及 rProgram）的性能。首先，给定一个 rTile，可以从 rTile 的张量表达式 expr 和形状静态推断出产生的内存占用（包括填充）和跨不同层的内存流量。它们用于计算数据重用分数并检查 rTile 是否超过内存容量。其次，为了计算 rTile 的 MaxComputePerf，ROLLER 进行一次性能分析，通过积极扩大计算瓦片（例如，SM 中的多个 warp 大小）来饱和 TEU，以测量峰值计算吞吐量。该性能数据被缓存到 ROLLER 中，以便在构建算法中进行未来查询。最后，对于给定的 rTile，ROLLER 还估计 MemPerf，即从内存层加载数据块到更高层的性能。鉴于 rTile 中对齐的内存访问，加载常规数据块的延迟可以简单地通过将总流量除以内存带宽来建模。对于所有 TEU 共享的内存层，我们将带宽平均分配。对于较小的访问大小，ROLLER 还对每种设备类型进行一次离线分析，并将结果缓存起来。**注意，微性能模型只需要在瓦片形状完全对齐时才需要准确，这是 ROLLER 的一个关键要求。**

11. 性能分析：Performance proﬁling，ROLLER 实现两个分析器：微性能分析器和内核分析器。前者通过一组微基准测试生成设备规格，例如内存带宽、计算吞吐量等，这是一种针对每种设备类型和张量表达式类型（无论张量形状如何）的一次性离线分析。后者分析前 K 个 rPrograms 中最快的内核，并在 K 大于 1 时用于每个编译结果。

---

## 个人思考

做一个性能评估模型而非实际上硬件测量，其最大好处之一就是前者速度快。低级IR的设计与实现要紧密考虑底层硬件，这是进行优化的一大方法。ROLLER 的设计思路颇具创新性，将深度学习的张量计算视为数据处理管道，不仅提高了性能评估的效率，还有效地对接了硬件特性。通过使用 rTile 进行构建和优化，ROLLER 实现了对内存层次结构的精细控制，最大化了资源利用率。这种方法的灵活性和高效性将推动深度学习模型在多种硬件上的部署，有望在实际应用中实现更高的性能和更低的延迟。


