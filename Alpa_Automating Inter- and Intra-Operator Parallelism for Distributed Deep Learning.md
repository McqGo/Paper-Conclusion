# Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning

# Alpa：自动执行分布式深度学习的跨算子和算子内并行

---

## 关键词

算子、并行、自动

---

## 核心思想

并行性很重要，而提高并行性的关键方法之一便是算子并行性。而算子并行性目前面临的挑战是用户手动创建并行化计划的局限性。为此，本文在分析算子并行性后，设计了一系列编译过程，以自动推导出每个独立并行级别中的最佳并行执行计划。并实现了一个高效的运行时来协调分布式计算设备上的两级并行执行。

---

## 主要工作

Alpa，一种基于机器学习并行化方法的新视角——算子内并行和算子间并行，构建的用于自动模型并行分布式训练的新架构。Alpa 构建了一个分层空间，并使用一组编译过程来推导出每个独立并行级别中的最佳并行执行计划。Alpa 在两种不同的粒度上协调分布式计算设备上的并行执行。为分布式模型并行深度学习制定高效的并行化计划历来是一项劳动密集型任务，Alpa 将使分布式模型并行学习简化，并加速新兴大型深度学习模型的采用。

---

## 学到的知识点

1. 并行化非常重要：高效的大规模模型训练需要在网络中各个算子的粒度上调整数据、算子和流水线并行化方法的复杂组合。正确调整并行化策略已被证明可以将训练性能提高一个数量级。当模型或数据过大以至于单个设备无法在合理的时间内完成训练时，我们求助于 ML 并行化方法，在分布式设备上并行计算。

2. 现有的模型并行训练系统：
   
   - 要么要求用户手动创建并行化计划
   
   - 要么从有限的模型并行配置空间中自动生成一个计划
   
   缺点：这不足以将复杂的 DL 模型扩展到分布式计算设备上。

3. 不考虑底层系统的并行化：自动并行化大规模模型将显著加速机器学习 (ML) 研究和生产，使模型开发者能够快速探索新的模型设计，而无需考虑底层系统挑战。但这需要在计划空间中进行导航，而该空间随着并行度的维度和模型和集群的大小呈指数增长。

4. **Alpa 设计了一系列编译过程，以自动推导出每个独立并行级别中的最佳并行执行计划，并实现了一个高效的运行时来协调分布式计算设备上的两级并行执行（算子间并行性与算子内并行性）**。在算子内级别，Alpa 在给定设备网格（即可能具有高带宽的设备集，例如单个服务器内的 GPU）上，针对其算子内并行计划，最小化执行计算图的阶段（即子图）的成本。根据分配的工作负载，不同的网格可能拥有不同数量的计算设备。在算子间级别，Alpa 针对如何将模型和设备集群切分成阶段和设备网格，以及如何将它们映射为阶段-网格对，最大程度地减少了算子间并行化延迟。跨算子优化依赖于了解由内部操作优化器报告的每个阶段-网格对的最佳执行成本。通过这种分层优化过程，Alpa 生成包含算子内和算子间计划的执行计划，这些计划在其各自的层次结构级别上是局部最优的。

5. Alpa 将并行性视为两个层次结构级别：
   
   - 算子间并行性：将模型切分成不相交的阶段，并将阶段的执行流水线化到不同的设备集上
   
   - 算子内并行性：沿任何张量轴（批处理或非批处理）对 ML 算子进行划分，并将划分后的部分分配到分布式设备上
   
   它们发生在模型计算的两个不同粒度上，区别在于是否对算子进行划分。
   
   两者的特点也不一样：
   
   - 算子内并行：具有更好的设备利用率，但在每次训练迭代中，在分区算子的每个拆分和合并处进行通信。由于分区，在算子的拆分和合并处需要进行集体通信。因此，算子内并行的一个关键特征是它会导致分布式设备之间大量的通信。
   
   - 算子间并行：仅在相邻阶段之间进行通信，如果切片得当，通信量可以很小，但由于调度约束，会导致设备空闲时间。在算子间并行中，设备仅在流水线阶段之间进行通信，通常使用成对设备之间的点对点通信。所需的通信量可能远小于算子内并行中的集体通信。无论使用何种调度，由于阶段之间的数据依赖性，算子间并行会导致一些设备在正向和反向计算期间处于空闲状态。

6. **作者的关键发现**：可以将不同的并行化技术组织成一个分层空间，并将这些并行化技术映射到计算集群的分层结构。不同的并行化技术对通信的带宽需求不同，而典型的计算集群具有相应的结构：位置接近的设备可以以高带宽进行通信，而距离较远的设备则具有有限的通信带宽。

7. Alpa的灵感：**利用计算集群中通信带宽的非对称性，将算子内部的并行性映射到具有高通信带宽的设备上，同时将算子之间并行性编排到具有相对较低带宽的远程设备之间**。这种分层设计允许我们以独立的可处理子问题的方式优化每个级别。虽然联合执行计划不能保证全局最优，但它们在训练各种大型模型方面表现出强大的性能。这就是Alpa的灵感。**两种并行性发生在 DL 计算的不同粒度上，并具有不同的通信需求，这恰好与当今典型计算集群的结构相匹配。作者利用这些特性来设计分层算法和编译过程，以自动生成执行计划。**

8. Alpa：第一个自动生成涵盖所有数据、算子、流水线并行的并行执行计划的编译器。给定模型描述和集群配置，Alpa 通过将集群划分为多个设备网格来实现这一点，每个设备网格包含具有较高带宽连接的设备，并将模型的计算图划分为多个阶段。它将阶段分配给设备网格，并自动协调设备网格上的算子内并行和设备网格之间的算子间并行。针对GPU集群。

9. 机器学习并行化方法：
   
   - 数据并行：Data parallelism，在数据并行中，训练数据被分配到分布式工作节点，但模型被复制。每个工作节点在其独立的数据分割上计算参数更新，并在权重更新之前将更新与其他工作节点同步，以便所有工作节点在整个训练过程中观察到一致的模型参数。
   
   - 算子并行：Operator parallelism，当模型过大无法容纳在一个设备中时，算子并行是一种有效的模型并行选项。算子并行是指将特定算子的计算沿着非批次轴进行划分，并在多个设备上并行计算算子的每个部分的方法。
   
   - 流水线并行：Pipeline parallelism，与对操作进行分区不同，流水线并行将模型图中不同的操作组（称为阶段）放置在不同的工作节点上；同时，它将训练批次拆分为多个微批次，并在分布式工作节点上对微批次进行前向和后向传递的流水线处理。与算子并行不同，流水线并行在正向和反向传播过程中使用点对点通信在不同的工作节点之间传递中间激活值。
   
   最近的发展表明，上述方法需要结合起来，才能扩展当今大型深度学习模型的规模。结合方法有2种：
   
   - 并行机制的手动组合：Manual combination of parallelisms，手动设计了一个专门的执行计划，将这些并行机制组合起来，用于 Transformer 语言模型。但手动计划无法推广到不同的模型或不同的集群设置。
   
   - **自动组合并行性：Automatic combination of parallelisms，每个并行性的配置、它们之间的相互依赖关系以及它们对模型和集群设置的依赖关系形成了一个难以处理的空间，这阻碍了自动组合这些并行性的简单实现。先前的自动并行化探索仅限于将数据并行与至多一种模型并行方法相结合，这错失了大量的性能机会。本论文就进行了新的探索。**

---

## 个人思考

本文针对分布式设备，依然是首先瞄准一类硬件，分析目前的不足，然后针对可能的优化方法进行详细地分析，通过数学方面的突破，结合硬件的特点，来找到合适的解决方法。由此可见，对硬件的了解、数学方面的理解，是研究AI编译器必须要掌握的。
