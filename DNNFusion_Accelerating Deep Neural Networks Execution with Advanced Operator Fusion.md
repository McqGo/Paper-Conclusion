# DNNFusion: Accelerating Deep Neural Networks Execution with Advanced Operator Fusion

# DNNFusion: 利用高级算子融合加速深度神经网络执行

---

## 关键词

算子、分类、循环融合

---

## 核心思想

DNNFusion将算子分类为不同的类型，并针对不同类型的组合制定规则，而不是寻找特定操作组合的模式。

---

## 主要工作

DNNFusion，一种新的循环融合框架。DNNFusion 提高了缓存性能和设备利用率，使其能够在资源更受限制的设备上执行。它还减少了编译期间的性能调优时间。并且首次允许许多以前端到端框架不支持的尖端 DNN 模型在移动设备上高效执行（甚至实时执行）。它的性能提升较大。

---

## 学到的知识点

1. DNNFusion的发展原因：深度神经网络 (DNN) 已成为移动设备上许多主要应用的核心推动力量。为了实现高精度，DNN 模型变得越来越深，拥有数百甚至数千个算子层，导致推理的内存和计算需求很高。算子融合（或内核/层融合）是许多最先进的 DNN 执行框架（例如 TensorFlow、TVM 和 MNN）的关键优化，旨在提高 DNN 推理的效率。但这些框架通常采用基于特定模式的融合方法，这些模式过于严格，无法涵盖算子和层连接的多样性。同时，基于多面体的循环融合技术在没有算子级信息的低级视图上工作，也可能错过潜在的融合机会。DNNFusion（循环融合框架）在 DNN 的算子视图上工作，通过对单个算子和它们的组合进行分类来扩展融合机会。主要三点原因：
   
   - 过去工作中考虑的融合模式过于受限，无法涵盖正在涌现的算子和层连接的多样性。
   
   - 基于多面体分析的循环融合的局限性
   
   - 传统的编译器循环变换与融合基于计算的低级视图，计算图中的运算符视图使我们能够利用这些计算的属性，这些属性在考虑计算的低级视图时可能会丢失。
   
   **DNNFusion 分别为移动 CPU 生成 C++ 代码，为移动 GPU 生成 OpenCL 代码。**

2. **基于多面体分析的循环融合的局限性**：
   
   - 多面体分析虽然为严格推理循环变换的合法性并探索其空间提供了极好的基础，但对于捕获 DNN 中相对简单的数据结构（张量）和操作（无循环依赖）来说可能过于“繁琐”。
   
   - 多面体分析通常局限于仿射循环分析和变换（尽管最新的努力确实将其扩展到某些非仿射循环优化），并且无法捕获 DNN 中的某些操作（组合）。

3. **算子融合（或内核/层融合）**：Operator fusion (or kernel/layer fusion)，提高 DNN 执行效率的一种常见方法。这种融合的基本思想与优化编译器所做的传统循环融合相同。有以下好处：
   
   - 消除不必要的中间结果
   
   - 减少不必要的输入扫描
   
   - 为其他优化机会创造条件

4. **DNNFusion的算子融合**：将算子分类为不同的类型，并针对不同类型的组合制定规则，而不是寻找特定操作组合的模式。首先根据其输入和输出之间的映射，将 DNN 中现有的操作划分为几个组，例如一对一、一对多等。将计算图表示增强为扩展计算图 (ECG) 表示。设计了一种映射类型分析，以推断融合不同类型运算符组合的操作的盈利能力，将组合分为三组：可能有利可图（且合法）、可能没有利可图，以及需要通过配置文件信息确定盈利能力的组合。然后，在 ECG 表示上，应用了一系列作者开发的图重写规则。与称为强度约简的经典优化类似。但与传统的编译器工作不同的是，作者将这些规则应用于张量上的运算（而不是标量），并且作者的规则远远超出了传统的规则。框架的其余部分包括用于确定特定操作融合（基于某些启发式方法）和生成优化融合代码的算法。

5. **深度神经网络（DNN）的趋势是朝着更深的方向发展。对移动设备内存和计算的要求越来越高**。**模型的深度是高效执行的关键障碍**。原因是：
   
   - 层数较多的模型通常会生成更多中间结果，从而增加内存/缓存压力。
   
   - 深度模型通常在每一层中计算量不足，从而降低了处理器的利用率，特别是对于 GPU 而言。
   
   随着计算量的增加，也出现了通过减小权重大小来减少计算量的趋势。机器学习研究人员通过减少每一层的权重大小，从而训练出更薄更深的模型，来平衡计算工作量和模型精度。而算子融合是一种可以有效减少内存需求并提高效率的技术。

6. DNN算子（ONNX（开放神经网络交换）支持的所有算子）的分类：每个算子的（每个）输入和输出之间的映射关系对于确定融合优化的可行性和正确实现至关重要。所以据此分类为5种高级抽象类型：
   
   - 一对一
   
   - 一对多
   
   - 多对多（包括多对一）
   
   - 重组（Reorganize）
   
   - 洗牌（Shuﬄe）
   
   如果一个算子只有一个输入，或者多个输入对输出具有相同的映射类型，那么该算子的映射类型由其任何输入/输出对决定。如果存在多个具有不同映射类型的输入/输出对，则该操作符的映射类型由更复杂的映射类型决定。

7. 融合机会分析：确定要融合的第一个和第二个算子的映射类型，以及结果算子的映射类型。将这种映射类型组合的融合分为三组（分别用绿色、黄色和红色表示）。
   
   - 绿色意味着这些融合是合法且有利可图的，不需要进一步分析
   
   - 红色意味着这些融合已知是非法的或显然不盈利的
   
   - 黄色表示这些融合是合法的，但是，需要进一步分析以确定盈利能力
   
   此分析消除了对红色和绿色情况进行任何时间运行时分析或自动调整的需要。对于剩余的（黄色）情况，作者使用存储离线收集的各种融合组合执行结果的分析数据库来进一步加速编译。

8. 转换阻抗：transformation impedance，定义为定量表达融合难度的指标。即当它们与另一种类型融合时，它们在决定融合后的映射类型方面具有不同的能力。一对一具有最低的转换阻抗，而重组和洗牌的转换阻抗处于中间，即它们可以将一对一转换为它们的类型，但不能转换其他类型。一对多和多对多具有最强的转换阻抗，即当它们与其他运算符融合时，结果映射类型完全由它们决定。此外，一对多和多对多具有相同的功能，重组和洗牌也具有相同的功能。

9. 扩展计算图 (ECG)：DNNFusion的中间表示。这种表示建立在 (传统) 计算图之上，后者捕获数据流和基本操作符信息，如操作符类型和参数。ECG 包含更多与融合相关的的信息，包括 mapping_type 指示每个操作符的映射类型，IR_removable 表示中间结果是否可以完全移除（只有当所有后继操作符都可以融合时才为真，并在融合过程中计算），以及操作的数学属性，例如是否满足结合律、交换律和/或分配律。

10. DNNFusion的工作流程：
    
    - 以编译器驱动的 DNN 执行框架（例如 TVM和 MNN）生成的计算图作为输入
    
    - 在输入上添加关键信息以创建扩展计算图 (ECG)，ECG就是IR
    
    - 基于数学性质的图重写（删除不必要的操作、消除冗余的中间数据副本、用更高效的操作替换代价高昂的 (组合) 操作）
    
    - 轻量级配置文件驱动的融合机会探索（采用一种新的轻量级（贪婪）方法来探索融合机会）
    
    - 融合代码生成和其他基于融合的先进优化

11. 轻量级配置文件驱动的融合机会探索：DNNFusion 从ECG 中选择起始算子（称为融合种子算子）来限制搜索空间。这是基于一个关键的洞察：一对一映射类型的算子有可能产生更多益处，因为它们 a) 可能导致更多层的融合，包括与它们的前驱和后继层的融合，这是由于我们所称的较低转换阻抗，以及 b) 在所有映射类型中具有较低的内存需求和对寄存器的需求。其次，从这些种子算子开始，DNNFusion 分别探索了种子算子的后继和前驱的融合机会。最后，DNNFusion 基于一种结合了机器无关映射类型分析和性能分析结果数据库的方法创建融合计划。映射类型分析查下表检查算子的映射类型组合（在 ECG 中），以决定是否应该融合这些算子。这种映射在大多数情况下消除了不必要的配置文件数据查找。
    
    ![](C:\Users\MCQSW\AppData\Roaming\marktext\images\2024-10-16-16-01-15-image.png)

12. 代码生成：一旦我们的算法选择了融合块，DNNFusion 就会使用从扩展计算图 (ECG) 构建的数据流树 (DFT) 和一组预定义的代码生成规则，为每个融合块生成融合代码。针对移动 CPU 和移动 GPU，分别定义了 23 条代码生成规则，每条规则对应上表中的一个绿色或黄色单元格。基本思想是，只要操作符类型相同，相同的规则就能生成高效的代码。在融合两个以上操作符时，每次融合两个操作符都会调用这些规则。最后，后续的代码优化（例如，矢量化、循环展开、平铺和内存/寄存器优化，以及这些优化的自动调整）由名为 PatDNN的现有框架处理。
    
    DNNFusion 首先从扩展计算图 (ECG) 生成一个数据流树 (DFT)。这个 DFT 表示最终输出 (Out)、所有中间结果 (IRS) 和所有输入 (A, B, C 和 D)，其边与 ECG 相反（即，父节点依赖于子节点）。在融合代码生成过程中，DNNFusion 递归地遍历此 DFT 以识别输入/输出数据依赖关系（并融合相应的 ECG 操作）。在该 DFT 遍历过程中，DNNFusion 使用预定义的代码生成规则为要融合的每对算子生成代码。

---

## 个人思考

DNNFusion的核心在于对算子融合进行了详尽的分析，并尽可能具体分析各种情况然后执行融合。算子融合优化的根本依据依然是硬件的特点。相比于其他DL编译优化框架算子融合的严格，DNNFusion因为它对算子进行了具体分析而变得更加灵活。
