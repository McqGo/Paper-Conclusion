# DeepCuts: A Deep Learning Optimization Framework for Versatile GPU Workloads

# DeepCuts：面向通用 GPU 工作负载的深度学习优化框架

---

## 关键词

剪枝、张量、内核、融合

---

## 核心思想

修剪掉（排除）肯定慢的候选项，所以该方法不是计算某方案的精确性能，而是判断它的最高性能。而性能评估模型是作者根据使用各种实现参数的张量操作手动 GPU 内核实现的经验建立。同时强调内核融合，以寻求更好的性能。

---

## 主要工作

该论文提出了一种名为DeepCuts的面向GPU负载的DL优化编译框架。该框架的提出背景是GPU是部署DL模型最常见的硬件，同时TVM等其他编译优化框架无法超越cuDNN，而cuDNN无法有力支持新兴计算操作。提出的DeepCuts旨在解决这一问题。DeepCuts有四个部分组成——候选生成器（划分合并节点，并为子集生成GPU内核）、性能评估器（评估该选项的最高性能）、代码生成器与代码选择器。它的性能评估器的模型由作者基于他们对使用各种实现参数的张量操作手动 GPU 内核实现的经验建立。

---

## 学到的知识点

1. **内核融合**（kernel fusion）指将多个连续的计算操作合并成一个更大、单一的计算操作。这种方法可以减少内存访问次数和中间结果的存储，从而提高计算效率。在深度学习中，常见的融合操作包括将卷积和激活函数、卷积和归一化等操作融合在一起。

2. **cuDNN的不足**：<u>cuDNN主要针对 CNN 推理和训练大量输入数据进行了优化，但新兴的深度学习应用可能需要加速不同的计算。</u>例如，各种类型的非卷积深度学习操作（例如，LSTM、GRU、嵌入等）正在快速发展并被广泛使用。cuDNN 尚未针对它们进行完全优化或缺乏支持。输入批次大小也很重要。<u>由于批次大小由 DNN 模型使用的环境决定，因此仅使用cuDNN 很难对所有批次大小进行同等良好的处理。</u>另一个问题是 <u>cuDNN 的内核融合功能有限</u>。内核融合是一种众所周知的优化技术，它通过将连续执行的内核合并成单个内核来减少 GPU 全局内存访问。cuDNN 仅支持少数 DL 工作负载模式的内核融合（例如，卷积、偏置加法和 ReLU 激活的序列）。然而，这不足以处理新兴深度学习工作负载中发现的各种深度学习操作模式。

3. **其他DL优化框架不能始终超越cuDNN的原因**：TVM、TensorFlow XLA、TensorRT与 cuDNN 相比，它们性能相对较低的主要原因是用于 GPU 内核优化的信息。为了优化 GPU 内核代码，程序员或代码生成器必须找到最佳性能的实现参数集，例如线程块的大小和输入特征图的平铺大小。然而，由于参数搜索空间太大，无法处理，因此几乎不可能为所有可能的参数集生成代码并测量其性能。

4. **DeepCuts一定超越或相当于cuDNN的原因**：一个是 DeepCuts 直接利用底层架构的信息（例如 GPU 共享内存的大小）来构建性能评估器。另一个是，DeepCuts 估计性能的上界而不是实际性能，并利用它来修剪肯定慢的案例，因为对于许多案例来说，估计实际性能非常困难且不准确。

5. 四种主要的DL优化框架，分为两类，第一类是高度依赖手工调优内核的框架（Google 的 TensorFlow XLA、NVIDIA 的 TensorRT），第二类是使用基于机器学习的优化来生成内核的框架（TVM和 Tensor Comprehensions）。第一类在某些特定模型上表现良好，但它们不适用于通用模型。第二类提出灵活的代码生成技术（即适用于通用模型），但其性能相对低于手工调优的库。DeepCuts 结合了两种类别的优势：灵活性和性能。在灵活性方面，DeepCuts 支持多种类型的深度学习操作，因为它使用不受限于特定深度学习操作的技术。在性能方面，DeepCuts 通过其依赖于架构感知性能估计模型的新颖优化技术，实现了与 cuDNN 相当或更好的性能。

6. TVM 在大批量推理中无法取得良好的性能，而 TensorFlow XLA 和 TensorRT 不适合小批量推理。

7. **DeepCuts与TASO的区别**：TASO侧重于转换张量操作的输入计算图，以获得更好的性能（例如，用一个更大的、更快的单矩阵乘法替换两个小的矩阵乘法）。TASO 和 DeepCuts 在某些方面有一些相似之处（例如，灵活的融合模式）。然而，我们并没有直接比较它们的性能，因为这两个框架之间存在显著差异。造成这种情况有两个原因。其一是 DeepCuts 和 TASO 的优化程度存在很大差异。TASO 并不专注于生成 GPU 内核。相反，它专注于重写计算图以更好地利用给定的原始库（例如，cuDNN 原始库）。另一方面，DeepCuts 主要专注于为给定的计算图生成优化的 GPU 内核。另一个原因是 DeepCuts 不会改变总计算量，而 TASO 会。DeepCuts 旨在执行架构感知优化，而不会改变总计算量本身（即 FLOPS）。TASO 执行各种高级图替换，这在许多情况下会改变总计算量。两种方法都有益，可以协同使用，但不适合直接比较。

8. 寻找一些重要深度学习操作（例如矩阵乘法和卷积）的优化代码的技术：广泛使用的 **BLAS 库**依赖于具有最佳实现参数集（例如，平铺大小）的预定义内核。这些参数是通过暴力搜索所有可能的案例来找到的。**OpenTuner 和 KernelTuner** 使用进化算法来寻找最佳参数。Pfaffe 等人将**进化算法和多面体模型相结合**，以生成最佳内核代码。

9. ![](C:\Users\MCQSW\AppData\Roaming\marktext\images\2024-10-11-21-14-27-image.png)

10. **DeepCuts的大致工作流程**：DeepCuts 由四个模块组成：候选生成器,、性能评估器,、代码生成器和代码选择器。候选生成器将给定深度学习工作负载的节点（即张量运算）集合进行划分。将节点分组为非空子集，使得每个节点恰好包含在一个子集中。每个子集包含单个节点或多个连续节点。DeepCuts 为每个子集生成一个单独的 GPU 内核。将多个节点放入一个子集中意味着对应于这些节点的 GPU 内核被融合成一个用于整个子集的单个内核。候选生成器生成多个分区作为代码生成候选，评估每个分区，并识别性能最佳的分区。为了检查分区中每个子集的性能，候选生成器使用其他模块：性能评估器、代码生成器和代码选择器。

11. 四个主要的体系结构相关的性能限制因素：（1）全局内存带宽（Global memory bandwidth，指每字节全局内存流量的计算操作数量），（2）共享内存延迟（Shared memory latency），（3）流式多处理器 (SM) 之间的负载不平衡（Worked imbalance across SMs，由于 DeepCuts 假设每个线程块执行相同数量的计算，因此线程块之间不存在工作负载不平衡。但是，当线程块的数量不是 SM 数量的倍数时，就会出现工作负载不平衡），(4) 硬件资源的限制（Limitation of hardware resources，当内核实现参数所需的硬件资源超过 GPU 提供的可用资源时，无法执行生成的内核代码）。

12. **DeepCuts的性能评估模型**：DeepCuts 中使用性能估计模型的目标不是估计精确的性能，而是利用性能估计模型来修剪那些肯定会减慢速度的案例，估计给定 GPU 架构参数和内核实现参数下张量操作性能的**上限**。该性能模型的构建基于上述4个因素，基于此信息，DeepCuts 可以无需实际生成和执行内核，就能剪枝掉那些肯定慢的内核。PUL 代表张量操作的预期最大性能与目标 GPU 的峰值理论性能之比。PUL 的值介于 0 和 1 之间。例如，假设对于给定的实现参数，PUL = 0.7。在这种情况下，我们无法使用给定的实现参数获得超过 GPU 理论峰值性能的 70%。

$$
PUL=GMRatio*SMRatio*WBRatio*COEFr
$$

13. 共享内存级和寄存器级融合：当分区中的一个节点子集包含两个连续节点时，性能估计模型通过考虑它们的融合来搜索实现参数。将两个连续操作（例如前驱和后继）融合有两种方式：在共享内存级别和寄存器级别。寄存器级融合将中间结果保存在寄存器中，而共享内存级融合将两个操作之间的中间结果存储在共享内存中。DeepCuts 使用一种简单、确定性的算法来选择融合方式。寄存器级融合应用于以下两种情况：一是两个简单操作的组合（例如，逐元素操作后接 ReLU）；二是简单操作和复杂操作的组合（例如，卷积操作后接偏置加法）。当后续操作符中的多个线程需要使用先前操作符中某个线程的计算结果时，使用共享内存级融合（例如，卷积操作后紧跟另一个卷积操作）。

14. 代码生成：DeepCuts 依赖于一种基于数据流图的代码生成算法，该算法使用 DFG 作为中间表示。DFG 生成包含三个步骤：（1）基线 DFG 生成，（2）DFG 连接，（3）为 GPU 线程提取子图。

---

## 个人思考

与TVM的跨后端硬件多样化不同，DeepCuts仅支持GPU硬件，所以它对GPU硬件特性的利用也更加注重。**这启示我未来在科研工作中，也许可以从特定的硬件开始研究，在特定的硬件上击败某些框架**。该框架采用排除法思想，排除一定最慢的方案，所以性能评估器评估的是方案的最高性能。同时，该框架的性能评估器模型建立在作者的大量手动工作经验上，这启示我在日后工作中要勤动手，或许一些灵感就来自于日常工作中。
